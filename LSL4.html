<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title></title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta
    name="apple-mobile-web-app-status-bar-style"
    content="black-translucent" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="reveal.js/css/reveal.css"/>
  <link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
  <link rel="stylesheet" href="main.css">
</head>
<body>

 <div class="reveal">
    <div class="slides">
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<section>
		<h1>Linear Systems</h1>
		<h2>Lecture 4</h2>
		<p style="font-size:48px; color: #00FF00">Jonathan Crofts</p>        
		<p style="color: #00FF00">Nottingham Trent University</p>
    </section>
	  <!-- ################################################### -->
      <!-- ################################################### -->
	<section align="left">
		<h1>Linear Systems L4</h1>
		<br>
		<ul>
			<span style="color: #00FF00"> 
			<li>Introduction to Jordan normal forms</li>
			</span>
			<br>
			<li>The 2 by 2 case</li>
			<br>
			<li>Examples</li><br>			
		</ul>
	</section>		
			
	<section>
		<section  align="left">					
			<h2>Similarity transformations and the Jordan normal form (JNF)</h2>					
					
			<p>The <em>Jordan matrix</em> (or block) $\displaystyle J_{n_i}(\lambda)$ is the $n_i\times n_i$ matrix with $\lambda$
			on the diagonal and ones directly above the diagonal, <em>i.e.</em></p>
			
			\[
			J_{n_i}(\lambda) = \begin{bmatrix}\lambda&1&0&\cdots &0\\ 0&\lambda&1&&0\\
			\vdots&\ddots&\ddots&\ddots&\\0&&&&1\\0&\cdots&&0&\lambda\end{bmatrix}\in\mathbb{R}^{n_i\times n_i}	
			\]			
			
			<br>
			<span class="fragment fade-in">
			<h3>Example 4.1</h3>
			\[
			 J_2(1) = \begin{bmatrix}1&1\\0&1\end{bmatrix} \quad J_3(-2) = \begin{bmatrix}-2&1&0\\0&-2&1\\0&0&-2\end{bmatrix}\quad\text{and}\quad J_1(3) = \begin{bmatrix}3\end{bmatrix}
			\]
			</span>
		</section>
		
		<section  align="left">	
		<p>We say that a matrix is in <em>Jordan normal form</em> (JNF) if it is a <em>block diagonal</em> matrix where the blocks are 
		Jordan blocks, that is</p>
		\[
		 J = \begin{bmatrix}J_{n_1}(\lambda_1)&&&\\&J_{n_2}(\lambda_2)&&\\&&\ddots&\\&&&J_{n_k}(\lambda_k)\end{bmatrix}\in\mathbb{R}^{n\times n}\quad\text{with}\quad n_1+n_2+\cdots +n_k=n
		\]
		
		<br>
		<span class="fragment fade-in">
		<h3>Note</h3>
		<p>Diagonal matrices are in JNF since we are allowed 1 by 1 blocks</p>
		</span>
		
		<span class="fragment fade-in">
	
		<h3>Example 4.2</h3>
		\[
		 \begin{bmatrix}3&0&0\\0&-2&1\\0&0&-2\end{bmatrix} = \begin{bmatrix}J_1(3)&\\&J_2(-2)\end{bmatrix}\qquad \begin{bmatrix}4&0\\0&5\end{bmatrix}=\begin{bmatrix}J_1(4)&\\&J_1(5)\end{bmatrix}
		\]
		</span>
		</section>
								
		<section  align="left">	
						
			<p>Importantly every matrix $\displaystyle A\in\mathbb{R}^{n\times n}$ is similar to a Jordan matrix $J$, that is</p>
			\[
			 A = PJP^{-1}
			\]
			<p>For some invertible matrix $P$</p>
					
			<span class="fragment fade-in">					
			<h3>Note</h3>
			
			<ol>
				<li>The matrix $J$ is unique upto a reordering of the blocks</li>
				<li class="fragment fade-in">$J$ and $A$ have the same characteristic and minimal polynomials</li>
				<li class="fragment fade-in">The diagonal entries of $J$ are the eigenvalues of $A$</li>
				<li class="fragment fade-in">The number of times $\lambda$ occurrs on the diagonal of $J$ equals the AM of $\lambda$</li>
				<li class="fragment fade-in">The size of the largest Jordan block containing $\lambda$ is equal to the number of times the factor $(t-\lambda)$ appears in $m_A(t)$</li>
				<span class="fragment fade-in">
				<li>If the factor $(t-\lambda)$ appears in the minimal polynomial with multiplicity $m$, then we define the <em>generalised eigenspace</em> as 
				<br><br>
				\[
				\color{red}{\boxed{\color{white}{
				 \mathrm{Ker}\left[(A-\lambda I_n)^m\right] = \left\{\mathbf{u}\in \mathbb{R}^{n}:(A-\lambda I_n)^m\mathbf{u}=0\right\}
				 }}}
				\]
				</span>
			</ol>			
		</section>			
				
	</section>		


	<section>
		<section align="left">
		<h2>Motivating generalised eigenspaces</h2>
		<p>Suppose we have a 2 by 2 matrix</p>
		\[
		 A=PJP^{-1}
		\]
		<p>where the matrix $J$ is of the form</p>
		\[
		 J = \begin{bmatrix}\lambda&1\\0&\lambda\end{bmatrix}
		\]
		<p>In this case we know that $A$ has eigenvalue $\lambda$ with AM=2 and GM=1</p>
		
		<span class="fragment fade-in">
		<p>Suppose that $P=\begin{bmatrix}\mathbf{u}_1&\mathbf{u}_2\end{bmatrix}$ then we can write</p>
		\[
		 \begin{align*}
		  A=PJP^{-1}\implies AP=PJ &\implies A\begin{bmatrix}\mathbf{u}_1&\mathbf{u}_2\end{bmatrix} = \begin{bmatrix}\mathbf{u}_1&\mathbf{u}_2\end{bmatrix}J\\
		  &\implies \begin{bmatrix}A\mathbf{u}_1&A\mathbf{u}_2\end{bmatrix} = \begin{bmatrix}\mathbf{u}_1&\mathbf{u}_2\end{bmatrix}\begin{bmatrix}\lambda&1\\0&\lambda\end{bmatrix}\\
		  &\implies \begin{bmatrix}A\mathbf{u}_1&A\mathbf{u}_2\end{bmatrix} = \begin{bmatrix}\lambda\mathbf{u}_1&\mathbf{u}_1+\lambda\mathbf{u}_2\end{bmatrix}
		 \end{align*}
		\]
		</span>
		</section>	
		
		<section align="left">
		<p>The columns in the matrix equation </p>
		\[
		\begin{bmatrix}A\mathbf{u}_1&A\mathbf{u}_2\end{bmatrix} = \begin{bmatrix}\lambda\mathbf{u}_1&\mathbf{u}_1+\lambda\mathbf{u}_2\end{bmatrix}
		\]		
		<p>must be equal and so </p>
		\[
		 \begin{align*}
		  A\mathbf{u}_1 =\lambda \mathbf{u}_1 &\implies (A-\lambda I_2)\mathbf{u}_1=0\\
		  A\mathbf{u}_2 =\mathbf{u}_1+\lambda \mathbf{u}_2 &\implies	(A-\lambda I_2)\mathbf{u}_2 = \mathbf{u}_1	  
		 \end{align*}
		\]
		<p>The first equation above is the usual eigenvalue-eigenvector equation for the vector $\mathbf{u}_1$</p>
		
		<span class="fragment fade-in">
		<p>However, the equation for $\mathbf{u}_2$ is no longer an eigenvalue-eigenvector equation</p>
		
		<p>It is a generalised eigenvalue-eigenvector equation and we call the vector $\mathbf{u}_2$ a <em>generalised eigenvector</em></p>
		</span>		
		</section>	
		
		<section align="left">		
		<p>Noting that </p>
		\[
		 (A-\lambda I_2)\mathbf{u}_2 = \mathbf{u_1}\implies (A-\lambda I_2)^2\mathbf{u}_2 = (A-\lambda I_2)\mathbf{u_1} = 0
		\]
		<p>we often solve instead</p>
		\[
		\color{red}{\boxed{\color{white}{
		 \begin{align*}
		  (A-\lambda I_2)\mathbf{u}_1 &= 0 \\
		  (A-\lambda I_2)^2\mathbf{u}_2 &= 0
		 \end{align*}
		 }}}
		\]
		<span class="fragment fade-in">
		<h3>Note</h3>
		<ol>
			<li>Vectors that solve the second equation are called <em>generalised eigenvectors</em></li>
			<li>The set of all such vectors, <em>i.e.</em>
			\[
			 \mathrm{Ker}\left[(A-\lambda I_2)^2\right] = \Biggl \{\mathbf{u}\in\mathbb{R}^2 : (A-\lambda I_2)^2\mathbf{u}=\mathbf{0}\Biggr \}
			\]
			is called the <em>generalised eigenspace</em></span>
			</li>
			<li class="fragment fade-in">For the two by two case above \[\mathrm{Ker}\left[(A-\lambda I_2)^2\right]=\mathbb{R}^2 \qquad\text{(Why?)}\]</li>			
			<li class="fragment fade-in">Importantly \[\mathrm{Ker}\left[(A-\lambda I_2)\right]\subset \mathrm{Ker}\left[(A-\lambda I_2)^2\right]\]</li>
		</ol>
		
		</section>	
	</section>			
	
	<section>
		<section align="left">
		<h3>Example 4.3</h3>
		<p>Suppose $\displaystyle A = \begin{bmatrix}5&4&2&1\\0&1&-1&-1\\-1&-1&3&0\\1&1&-1&2\end{bmatrix}$</p>
		
		<p>It can be shown that $\lambda_1=1, \lambda_2=2$ and $\lambda_{3,4}=4$</p>
		
		<span class="fragment fade-in">
		<p>We want to determine the GM of $\lambda=4$ and so we solve</p>
		\[
		 (A-4I_4)\mathbf{u}=\mathbf{0}
		\]
		<p>Row operations can be used to reduce $A-4I_4$ as follows (exercise)</p>
		\[
		 A-4I_4 = \begin{bmatrix}1&4&2&1\\0&-3&-1&-1\\-1&-1&-1&0\\1&1&-1&-2\end{bmatrix}\longrightarrow \begin{bmatrix}1&4&2&1\\0&1&1&1\\0&0&1&1\\0&0&0&0\end{bmatrix}
		\]
		<p class="fragment fade-in">It follows that the vector $\displaystyle \mathbf{u} = \begin{bmatrix}\alpha&0&-\alpha&\alpha\end{bmatrix}^T$</p>
		</span>
		</section>	
		
		<section align="left">		
		<p> The eigenspace corresponding to $\lambda=4$ is given by </p>
		\[
		 \Biggl \{ \alpha\begin{bmatrix}1&0&-1&1\end{bmatrix}^T: \alpha\in\mathbb{R} \Biggr \}
		\]
		<p>so that the GM=1</p>
		<span class="fragment fade-in">
		<p>It follows that $A$ is <em>not</em> diagonalisable; however, it does have a JNF such that</p>
		\[
		A = P\begin{bmatrix}1&0&0&0\\0&2&0&0\\0&0&4&1\\0&0&0&4\end{bmatrix}P^{-1} = P\begin{bmatrix}J_1(1)&&\\&J_1(2)&\\&&J_2(4)\end{bmatrix}P^{-1}
		\]
		</span>
		<span class="fragment fade-in">
		<p>Also</p>
		\[
		 \chi_A(t)=m_A(t)=(t-1)(t-2)(t-4)^2
		\]
		</span>
		<br>
		<b class="fragment fade-in" style="color:red">In the lectures to come we shall learn how to compute the similarity transformation $P$ in the case of a general nondiagonalisable matrix $A$</b>
		</section>					
	</section>

	<!-- ################################################### -->
    <!-- ################################################### -->
	<section align="left">
		<h1>Linear Systems L4</h1>
		<br>
		<ul>			
			<li>Introduction to Jordan normal forms</li>			
			<br>
			<span style="color: #00FF00"> 
			<li>The 2 by 2 case</li>
			</span>
			<br>
			<li>Examples</li><br>			
		</ul>
	</section>
	<!-- ################################################### -->
    <!-- ################################################### -->

	<section>
		<section align="left">
		<h2>Finding the JNF of a 2 by 2 matrix</h2>
		<p>Suppose that $A\in\mathbb{R}^{2\times 2}$ there are two cases</p>
		
		<h3>Case 1</h3>
		\[
		\chi_A(t)=(t-\lambda_1)(t-\lambda_2)
		\]
		<p>In this case $J$ is diagonal and given by</p>
		\[
		J = \begin{bmatrix}\lambda_1&0\\0&\lambda_2\end{bmatrix}
		\]
		<p>Here the eigenvalues are distinct and AM=GM=1 in both cases</p>
		</section>	
				
		
		<section align="left">
		<h3>Case 2</h3>
		\[
		\chi_A(t)=(t-\lambda)^2
		\]
		<p>To start we compute the eigenspace corresponding to $\lambda$</p>
		
		<span class="fragment fade-in">
		<p>If the GM equals 2 then</p>
		\[
		 J = \begin{bmatrix}\lambda&0\\0&\lambda\end{bmatrix}
		\]
		</span>
		
		<span class="fragment fade-in">
		<p>Otherwise we consider the generlaised eigenspace, <em>i.e.</em> find solutions of</p>
		\[
		 (A-\lambda I_2)^2\mathbf{u}=\mathbf{0}
		\]
		<p>In this case</p>
		\[
		 J = \begin{bmatrix}\lambda&1\\0&\lambda\end{bmatrix}
		\]
		</span>
		</section>
		<section align="left">		
		<p>To find a basis of eigenvectors and generalised eigenvectors we proceed as follows</p>
		
		<ol>
			<li>Choose a vector $\mathbf{v}$ that does <em>not</em> belong to the $\lambda$-eigenspace</li><br>
			<li>Define
			\[
			\mathbf{u} = (A-\lambda I_2)\mathbf{v}
			\]
			</li><br>
			<li>Construct the matrix $P$ as 
			\[
			 P = \begin{bmatrix}\mathbf{u}&\mathbf{v}\end{bmatrix}
			\]
			</li><br>
			<li>Check that
			\[
			 P^{-1}AP=J
			\]
			</li>
		</ol>
		</section>		
	</section>

	<!-- ################################################### -->
    <!-- ################################################### -->
	<section align="left">
		<h1>Linear Systems L4</h1>
		<br>
		<ul>			
			<li>Introduction to Jordan normal forms</li>			
			<br>			
			<li>The 2 by 2 case</li>			
			<br>
			<span style="color: #00FF00"> 
			<li>Example</li><br>	
			</span>			
		</ul>
	</section>	
	<!-- ################################################### -->
    <!-- ################################################### -->
	
	<section>
		<section align="left">
		<h3>Example 4.4</h3>
		<p>Compute the Jordan normal form of the matrix</p>
		\[
		A = \begin{bmatrix}4&1\\-1&6\end{bmatrix}
		\]
		<br>
		<h3>Solution</h3>
		<span class="fragment fade-in">
		<p>To start let us compute the eigenvalues of $A$</p>
		\[
		\chi_A(t) = \begin{vmatrix}4-t&1\\-1&6-t\end{vmatrix} = (4-t)(6-t)+1 = t^2-10t+25=\color{red}{\boxed{\color{white}{(t-5)^2}}}
		\]
		</span>
		
		<span class="fragment fade-in">
		<p> The AM for $\lambda=5$ is two</p> 		
		
		<p>To determine $J$ we need to know the GM</p>
		</span>
		</section>	
		
		<section align="left">
		<p>Let us determine the corresponding eigenspace</p>
		\[
		 A-5I_2 = \begin{bmatrix}-1&1\\-1&1\end{bmatrix} \longrightarrow \begin{bmatrix}1&-1\\0&0\end{bmatrix}
		\]
		<p>The eigenspace is thus given by</p>
		\[
		\Biggl \{ \alpha\begin{bmatrix}1\\1\end{bmatrix} : \alpha\in\mathbb{R} \Biggr \}
		\]
		<img style="margin:0px;padding:0px;border: 3px solid #00FF00;position:absolute;top:200px;left:700px"				
				height="300"		
				src="figures/Ex4p4.png">
		<span class="fragment fade-in">		
		<p>And so the GM of $\lambda=5$ is 1 and so less than the AM</p>	
		<p>We need to compute a generalised eigenvector</p>
		<p><em>i.e.</em> a vector such that</p>
		\[
		(A-5I_2)^2\mathbf{u}=0
		\]
		<p>By Cayley-Hamilton any vector $\mathbf{v}\in\mathbb{R}^2$ satisfes the above equation</p>
		</span>
		</section>	
		
		<section align="left">
		<p>From the previous slide we see that we are free to set $\mathbf{v}$ equal to any vector that is not a 
		multiple of $\begin{bmatrix}1&1\end{bmatrix}^T$</p>
		
		<span class="fragment fade-in">
		<p>Choose as our generalised eigenvector</p>
		\[
		 \mathbf{v} = \begin{bmatrix}1&0\end{bmatrix}^T
		\]
		<p>This is the simplest vector satisfying $(A-5I_2)^2\mathbf{v}=0$ that does not lie in the $\lambda$-eigenspace</p>
		</span>
		
		<span class="fragment fade-in">
		<p>We need to choose a <em>related</em> eigenvector, <em>i.e.</em> $\mathbf{u}$ and $\mathbf{v}$ must satisfy the equation</p>
		\[
		 (A-5I_2)\mathbf{v}=\mathbf{u}
		\]
		<p>So we choose</p>
		\[
		\begin{align*}
		\mathbf{u} &= (A-5I_2)\mathbf{v} = \begin{bmatrix}-1&1\\-1&1\end{bmatrix}\begin{bmatrix}1\\0\end{bmatrix} =\begin{bmatrix}-1\\-1\end{bmatrix}\\\\
		&\implies \color{red}{\boxed{\color{white}{P=\begin{bmatrix}\mathbf{u}&\mathbf{u}\end{bmatrix}^T = \begin{bmatrix}-1&1\\-1&0\end{bmatrix}}}}
		\end{align*}
		\]
		</span>
		</section>		
	</section>
	
	<!-- ################################################### -->
    <!-- ################################################### -->
	<section>
		<h2 style="color:#00FF00">Lecture 4 Review</h2>
										
		<br>
		
		<ul>			
		<ul>						
			<li>In this lecture we covered</li>
			<ul>
				<li>computing the Jordan Normal Form of a matrix</li>				
			</ul><br>
			<li>After this lecture you should </li>
		<ul>
			<li>understand what a generalised eigenspace is</li>
			<li>be able to compute the JNF of a 2 by 2 matrix</li>						
		</ul><br>					
		</ul>			
		</ul>
		
	</section>
	<!-- ################################################### -->
	<!-- ################################################### -->
    </div>
 </div>
 <!-- ################################################### -->
 <!-- ################################################### -->
 <!-- ################################################### -->
 <!-- ################################################### -->
 <script src="reveal.js/lib/js/head.min.js"></script>
 <script src="reveal.js/js/reveal.js"></script>
 <script>
 // Full list of configuration options available here:
 // https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
          // width: 960,
          // height:700,
          controls: true,
          progress: true,
          history: true,
          center: true,
          theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
          // default/cube/page/concave/zoom/linear/fade/none
          transition: Reveal.getQueryHash().transition || 'slide',

          //// Optional libraries used to extend on reveal.js
          dependencies: [
            // { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
            // { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
            { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; }},
            { src: 'reveal.js/plugin/math/math.js', async: true }
          ]
        });
        Reveal.configure({
          keyboard: {
            32: null // don't do anything when SPACE is pressed (i.e. disable a reveal.js default binding) document.body.style.cursor = 'none';
          }
        });
        </script>
		<!-- ################################################### -->
        <!-- ################################################### -->
        </div>
        </div>
        <!-- ################################################### -->
        <!-- ################################################### -->
        <!-- ################################################### -->
        <!-- ################################################### -->
</body>
</html>