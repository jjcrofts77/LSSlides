<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title></title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta
    name="apple-mobile-web-app-status-bar-style"
    content="black-translucent" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="reveal.js/css/reveal.css"/>
  <link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
  <link rel="stylesheet" href="main.css">
</head>
<body>

 <div class="reveal">
    <div class="slides">
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<!-- ################################################### -->
	<section>
		<h1>Linear Systems</h1>
		<h2>Lecture 6</h2>
		<p style="font-size:48px; color: #00FF00">Jonathan Crofts</p>        
		<p style="color: #00FF00">Nottingham Trent University</p>
    </section>
	  <!-- ################################################### -->
      <!-- ################################################### -->
	<section align="left">
		<h1>Linear Systems L6</h1>
		<br>
		<ul>
			<span style="color: #00FF00"> 
			<li>Jordan normal form examples</li></span>	
			<br>
			<ul>
				<li style="color: #00FF00">2 by 2 case</li><br>							
				<li>3 by 3 case</li>
			</ul>			
		</ul>
	</section>			
			
			
	<section>
		<section  align="left">												
				<h3>Example 6.1</h3>		 
				<p>Compute the JNF of the matrix</p>
				\[
				 A = \begin{bmatrix}10&-1\\16&2\end{bmatrix}
				\]
								
				
				<h3>Solution</h3>
				
				<span class=fragment fade-in>
				<p>Compute the characteristic polynomial</p>
				\[
				\begin{align*}
				 \chi_A(t)&=\begin{vmatrix}10-t&-1\\16&2-t\end{vmatrix}\\
				 &=(10-t)(2-t)+16\\ &= t^2-12t+36 = \color{red}{\boxed{\color{white}{ (t-6)^2}}}
				\end{align*}
				\]
				<p>Thus $\lambda=6$ with AM=2</p>
				</span>
				
		</section>
				
		<section  align="left">		
			<p>We need to compute the eigenspace so we solve</p>
			\[
			 (A-6I_2)\mathbf{u}=\mathbf{0} \implies \begin{bmatrix}4&-1\\16&-4\end{bmatrix}\mathbf{u}=\mathbf{0}
			\]		
			<p>This is equivalent to $4u^{(1)}-u^{(2)}=0$</p>	
			
			<span  class="fragment fade-in">
			<p>Setting $u^{(2)}=4\alpha$ we get that $u^{(1)}=\alpha$ and so the eigenspace is</p>
			\[
			\Biggl \{ \alpha\begin{bmatrix}1\\4\end{bmatrix} : \alpha\in\mathbb{R} \Biggr \}
			\]
			<img style="margin:0px;padding:0px;border: 3px solid #00FF00;position:absolute;top:200px;left:850px"				
			height="400" src="figures/Ex6p1.png">
			<p>The GM=1</p>
			</span>
			<span  class="fragment fade-in">
			<p>We need to find a generalised eigenvector $\mathbf{v}$</p>
			
			<p>In the 2 by 2 case we know that $\displaystyle \mathrm{Ker}\left[(A-6I_2)^2\right]=\mathbb{R}^2$</p>
			
			</span>
		</section>
		
		<section  align="left">		
			<p>We are free to choose $\mathbf{v}$ to be any vector not in the $\lambda$-eigenspace</p>
			
			<p>Let us set</p>
			\[
			 \mathbf{v} = \begin{bmatrix}1\\0\end{bmatrix}
			\]
			<p>To get a related eigenvector we set $\mathbf{u}$ equal to</p>
			\[
			\mathbf{u} = (A-6I_2)\mathbf{v} = \begin{bmatrix}4&-1\\16&-4\end{bmatrix}\begin{bmatrix}1\\0\end{bmatrix} = \begin{bmatrix}4\\16\end{bmatrix}
			\]
			<span class="fragment fade-in">
			<p>So that $\displaystyle \color{red}{\boxed{\color{white}{ P=\begin{bmatrix}\mathbf{u}&\mathbf{v}\end{bmatrix} = \begin{bmatrix}4&1\\16&0\end{bmatrix}}}}$</p>
			</p>
			</span>
			
			<span class="fragment fade-in">
			<p>It is an exercise to check that $\displaystyle P^{-1}AP=\begin{bmatrix}6&1\\0&6\end{bmatrix} = J_2(6)=J$</p>
			</p>
			</span>
		</section>	
	</section>	
			
	<!-- ################################################### -->
    <!-- ################################################### -->				
	<section align="left">
		<h1>Linear Systems L6</h1>
		<br>
		<ul>
			<span style="color: #00FF00"> 
			<li>Jordan normal form examples</li></span>	
			<br>
			<ul>
				<li>2 by 2 case</li><br>							
				<li style="color: #00FF00">3 by 3 case</li>
			</ul>			
		</ul>
	</section>			
	
		<section>
			<section  align="left">												
				<h3>Example 6.2</h3>		 
				<p>Compute the JNF of the matrix</p>
				\[
				 A = \begin{bmatrix}5&-1&-3\\1&2&-1\\1&0&1\end{bmatrix}
				\]
								
				
				<h3>Solution</h3>
				
				<span class=fragment fade-in>
				<p>Compute the characteristic polynomial</p>
				\[
				\begin{align*}
				 \chi_A(t)&=\begin{vmatrix}5-t&-1&-3\\1&2-t&-1\\1&0&1-t\end{vmatrix}\\
				 &=\begin{vmatrix}-1&-3\\2-t&-1\end{vmatrix}+(1-t)\begin{vmatrix}5-t&-1\\1&2-t\end{vmatrix}\\
				 &=-t^3+8t^2-21t+18\implies \color{red}{\boxed{\color{white}{t^3-8t^2+21t-18 = (t-3)^2(t-2) = 0}}}
				\end{align*}
				\]
				<p class="fragment fade-in">Thus $\lambda_1=2$ with an AM=1 and $\lambda_2=3$ with an AM=2</p>
				</span>
							
			
				
		</section>
				
		<section  align="left">												
			<p>The $\lambda_1$-eigenspace is found by solving</p>
			\[
			 (A-2I_3)\mathbf{u}_1=\mathbf{0}\implies \begin{bmatrix}3&-1&-3\\1&0&-1\\1&0&-1\end{bmatrix}\mathbf{u}_1=\mathbf{0}
			\]
			<span class="fragment fade-in">
			<p>We see immediately that $u_1^{(1)}=u_1^{(2)}=\alpha$ and that $u_1^{(3)}=0$ giving </p>			
			\[
			\Biggl \{ \alpha\begin{bmatrix}1\\0\\1\end{bmatrix} : \alpha\in\mathbb{R} \Biggr \}
			\]
			</span>
			
			<span class="fragment fade-in">
			<p>The $\lambda_2$-eigenspace is found by solving</p>
			\[
			 (A-3I_3)\mathbf{u}_2=\mathbf{0}\implies \begin{bmatrix}2&-1&-3\\1&-1&-1\\1&0&-2\end{bmatrix}\mathbf{u}_2=\mathbf{0}
			 \implies \begin{bmatrix}1&0&-2\\0&1&-1\\0&0&0\end{bmatrix}\mathbf{u}_2=\mathbf{0}
			\]	
			<p>So $u_2^{(3)}=u_2^{(2)}=\alpha$ and $u_2^{(1)}=2\alpha$</p>
			</span>			
		</section>
		
		<section  align="left">												
		<p>The $\lambda_2$-eigenspace is</p>
		\[
		\Biggl \{ \alpha\begin{bmatrix}2\\1\\1\end{bmatrix} : \alpha\in\mathbb{R} \Biggr \}
		\]
		<p>And so $\lambda_2=3$ has a GM=1<2=AM</p>
		
		<span class="fragment fade-in">
		<p>We need to find a generalised eigenvector $\mathbf{v}$ such that</p>
		\[		 
		 (A-3I_3)\mathbf{u}=\mathbf{0} \quad\text{and}\quad (A-3I_3)\mathbf{v}=\mathbf{u}	 		
		\]
		</span>
		<span class="fragment fade-in">
		<p>To do this we find $\displaystyle \mathrm{Ker}\left[(A-3I_3)^2\right]$, that is, the solution space of $\displaystyle (A-3I_3)^2\mathbf{v}=\mathbf{0}$</p>
		</span>
		<span class="fragment fade-in">
		<p>Now</p>
		\[
		\quad(A-3I_3)^2 = \begin{bmatrix}0&-1&1\\0&0&0\\0&-1&1\end{bmatrix}\implies \begin{bmatrix}0&-1&1\\0&0&0\\0&0&0\end{bmatrix}\begin{bmatrix}v^{(1)}\\v^{(2)}\\v^{(3)}\end{bmatrix} = \mathbf{0}
		\]
		<p>So that $v^{(3)}=v^{(2)}=\alpha$ and $v^{(1)}=\beta$ giving $\color{red}{\boxed{\color{white}{\mathbf{v}=\begin{bmatrix}\beta &\alpha & \alpha\end{bmatrix}^T}}}$</p>
		</span>
		</section>
		
		<section  align="left">		
		<p>The generalised eigenspace is</p>
		\[
		\Biggl \{ \alpha\begin{bmatrix}0\\1\\1\end{bmatrix}+\beta \begin{bmatrix}1\\0\\0\end{bmatrix} : \alpha, \beta\in\mathbb{R} \Biggr \}
		\]
		<p>Clearly, the $\lambda_2$-eigenspace lies within the generalised space given above</p>
		
		<span class="fragment fade-in">
		<p>Next we need to pick a generalised eigenvector that is <em>not</em> an eigenvector</p>
		
		<p>Let</p>
		\[
		 \mathbf{v}=\begin{bmatrix}1\\0\\0\end{bmatrix} \implies \mathbf{u}=\begin{bmatrix}2&-1&-3\\1&-1&-1\\1&0&-2\end{bmatrix}\begin{bmatrix}1\\0\\0\end{bmatrix} = \begin{bmatrix}2\\1\\1\end{bmatrix}
		\]
		<p>So that</p>
		\[
		\color{red}{\boxed{\color{white}{
		 P = \begin{bmatrix}\mathbf{u}_1&\mathbf{u}&\mathbf{v}\end{bmatrix} = \begin{bmatrix}1&2&1\\0&1&0\\1&1&0\end{bmatrix}
		 }}}
		\]
		</span>
		</section>
	</section>
	
		<section>
		<section  align="left">												
				<h3>Example 6.3</h3>		 
				<p>Compute the JNF of the matrix</p>
				\[
				 A = \begin{bmatrix}0&1&2\\0&0&3\\0&0&0\end{bmatrix}
				\]
								
				
				<h3>Solution</h3>
				
				<span class=fragment fade-in>
				<p>Compute the characteristic polynomial</p>
				\[
				\begin{align*}
				 \chi_A(t)&=\begin{vmatrix}t&-1&-2\\0&t&-3\\0&0&t\end{vmatrix}\\
				 &= \color{red}{\boxed{\color{white}{ t^3}}}				 
				\end{align*}
				\]		
				<p>Thus $\lambda=0$ with an AM=3</p>
				</span>
				
		</section>
				
		<section  align="left">		
			<p>Let us compute the corresponding eigenspace</p>
			\[
			 (A-\lambda t)\mathbf{u}=0 \implies \begin{bmatrix}0&1&2\\0&0&3\\0&0&0\end{bmatrix}\begin{bmatrix}u^{(1)}\\u^{(2)}\\u^{(3)}\end{bmatrix}=0
			\]
			<p>Thus  $u^{(3)}=u^{(2)}=0$ and $u^{(1)}=\alpha$ so that the $\lambda$-eigenspace is</p>
			\[
			\color{red}{\boxed{\color{white}{
			 \Biggl \{ \alpha\begin{bmatrix}1\\0\\0\end{bmatrix} : \alpha\in\mathbb{R} \Biggr \}
			 }}}
			\]
			<p>The GM=1</p>
			
			<span class="fragment fade-in">
			<p>Let us look at the generalised eigenspace given by</p>
			\[
			 A^2\mathbf{v}=\mathbf{0}\implies \begin{bmatrix}0&0&3\\0&0&0\\0&0&0\end{bmatrix}\begin{bmatrix}v^{(1)}\\v^{(2)}\\v^{(3)}\end{bmatrix}=0
			 \quad \text{or}\quad \color{#00FF00}{\boxed{\color{white}{\Biggl \{ 
			 \alpha\begin{bmatrix}1\\0\\0\end{bmatrix}+\beta\begin{bmatrix}0\\1\\0\end{bmatrix} : \alpha\in\mathbb{R} \Biggr \}}}}
			\]
			</span>
		</section>
		
		<section  align="left">	
		<p>We still require another generalised eigenvector so we consider</p>
		\[
		 A^3\mathbf{w}=\mathbf{0}
		\]
		<p>By CH we know that $A^3=0$ so the above equation is satisfied for all $\mathbf{w}\in\mathbb{R}^3$</p>
		
		<span class="fragment fade-in">
		<p>That is</p>
		\[
		\color{red}{\boxed{\color{white}{
		 \mathrm{Ker}\left[A^3\right] = \mathbb{R}^3
		 }}}
		\]
		</span>
		
		<span class="fragment fade-in">
		<p> We choose $\mathbf{w}$ so that it does not lie in $\displaystyle\mathrm{Ker}\left[A^2\right]$, say</p>
		\[
		 \mathbf{w}=\begin{bmatrix}0\\0\\1\end{bmatrix}\implies \mathbf{v} = \begin{bmatrix}0&1&2\\0&0&3\\0&0&0\end{bmatrix}\begin{bmatrix}0\\0\\1\end{bmatrix} = \begin{bmatrix}2\\3\\0\end{bmatrix}
		 \implies \mathbf{u} = \begin{bmatrix}0&1&2\\0&0&3\\0&0&0\end{bmatrix}\begin{bmatrix}2\\3\\0\end{bmatrix} = \begin{bmatrix}3\\0\\0\end{bmatrix}
		\]
		</span>
		
		<span class="fragment fade-in">
		<p>Thus</p>		
		\[
		\color{#00FF00}{\boxed{\color{white}{
		 P = \begin{bmatrix}\mathbf{u}&\mathbf{v}&\mathbf{w}\end{bmatrix} = \begin{bmatrix}3&2&0\\0&3&0\\0&0&1\end{bmatrix}
		 }}}
		\]
		</section>
				
	</section>
	
	
			
	<section>
		<h2 style="color:#00FF00">Lecture 6 Review</h2>
		<br>		
		<ul>						
					<li>In this lecture we covered</li>
					<ul>
						<li>examples of computing the JNF for 2 by 2 and 3 by 3 matrices</li>
					</ul><br>
					<li>After this lecture you should</li>
					<ul>
						<li>be able to compute the JNF of matrices up to dimension 3</li>						
					</ul><br>					
		</ul>			
			
	</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
				// Learn about plugins: https://revealjs.com/plugins/
			plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
		});
	</script>
          <script src="plugin/math/math.js"></script>
          <script>
            Reveal.initialize({ plugins:[ RevealMath.KaTeX ] });
          </script>
</body>
</html>